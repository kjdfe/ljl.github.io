WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:03.435
现在 我们已经创建了一个完整的分类器

00:00:03.435 --> 00:00:08.029
它可以读了一个 RGB 图像 并输出任何图像的预测标签

00:00:08.029 --> 00:00:11.039
接下来 我们要看看模型的准确度

00:00:11.039 --> 00:00:16.864
分类模型的准确度可以通过预测标签和真实标签的对比确定

00:00:16.864 --> 00:00:19.214
如果预测标签和真实标签相吻合

00:00:19.214 --> 00:00:21.570
就表示图像分类正确

00:00:21.570 --> 00:00:23.579
否则 就表示分类错误

00:00:23.579 --> 00:00:25.949
准确度是指分类正确的图像

00:00:25.949 --> 00:00:29.320
占图像总数的比例

00:00:29.320 --> 00:00:32.085
因为我们这里使用的亮度特征非常简单

00:00:32.085 --> 00:00:35.804
我们预期这个分类器不会 100% 准确

00:00:35.804 --> 00:00:38.850
我们还会在新图像上测试分类器

00:00:38.850 --> 00:00:41.189
我们将其称作数据测试集

00:00:41.189 --> 00:00:44.489
测试数据是之前没见过的图像数据

00:00:44.490 --> 00:00:46.679
之前见过、用来构建分类器的数据

00:00:46.679 --> 00:00:49.375
叫做训练数据

00:00:49.375 --> 00:00:52.064
在训练数据中 是这些图像

00:00:52.064 --> 00:00:56.129
之所以要创建这两个集 训练集和测试集

00:00:56.130 --> 00:01:00.830
是需要一个集进行学习 另一个集用于测试分类器

00:01:00.829 --> 00:01:02.969
假设我们创建了一个分类器

00:01:02.969 --> 00:01:05.670
可以正确对所有训练图像分类

00:01:05.670 --> 00:01:09.840
但你实际上想构建一个分类器 能识别通用图案

00:01:09.840 --> 00:01:14.560
和数据 保证分类器在面临真实长颈是也能正常工作

00:01:14.560 --> 00:01:17.850
因此 我们会载入一个新的数据测试集

00:01:17.849 --> 00:01:21.324
看看分类模型在真实世界中的表现

00:01:21.325 --> 00:01:24.674
从而确定模型的准确度

00:01:24.674 --> 00:01:27.435
我们载入测试图像 对其归一化处理

00:01:27.435 --> 00:01:31.950
然后打乱重置 保证顺序对测试准确度不起作用

00:01:31.950 --> 00:01:33.945
要确定准确度

00:01:33.944 --> 00:01:36.204
我需要遍历这个测试数据

00:01:36.204 --> 00:01:38.525
我需要使用一个函数

00:01:38.525 --> 00:01:42.644
get_misclassified_images 代入我的测试图像

00:01:42.644 --> 00:01:46.289
刚开始时 我使用一个空列表 misclassified_images_labels

00:01:46.290 --> 00:01:49.660
然后遍历测试图像集中的每幅图像

00:01:49.659 --> 00:01:51.390
提取真实数据

00:01:51.390 --> 00:01:53.424
图像和真实标签

00:01:53.424 --> 00:01:56.069
然后 运行分类器代码 使用估算标签函数并代入图像

00:01:56.069 --> 00:02:01.049
得到预测标签

00:02:01.049 --> 00:02:02.534
因此 对于任何图像 我们都使用

00:02:02.534 --> 00:02:06.984
分类代码产生一个该图像的预测标签

00:02:06.984 --> 00:02:10.134
然后 我会对比预测标签和真实标签

00:02:10.134 --> 00:02:12.849
如果两者吻合 则图像分类正确

00:02:12.849 --> 00:02:14.155
否则

00:02:14.155 --> 00:02:16.155
图像分类错误

00:02:16.155 --> 00:02:19.060
接下来 我会把分类错误的图像、它们的预测值

00:02:19.060 --> 00:02:23.069
和真实数值添加到一个列表 misclassified_images_labels

00:02:23.069 --> 00:02:24.655
再次附加图像

00:02:24.655 --> 00:02:27.379
其预测标签和真实标签

00:02:27.379 --> 00:02:32.069
最后 返回所有错误分类的图像及其标签的列表

00:02:32.069 --> 00:02:35.109
然后 我来计算准确度

00:02:35.110 --> 00:02:38.025
首先 在归一化的图像测试列表中

00:02:38.025 --> 00:02:40.605
运行这个函数 get_misclassified_images

00:02:40.604 --> 00:02:45.514
这些图像全部保存为一个分类图像和标签列表 Misclassified

00:02:45.514 --> 00:02:48.179
然后 存储图像总数量

00:02:48.180 --> 00:02:51.189
只需获得归一化测试列表的长度即可

00:02:51.189 --> 00:02:53.669
正确分类的图像等于

00:02:53.669 --> 00:02:57.780
总数量减去错误分类的图像数量

00:02:57.780 --> 00:03:01.185
最后 计算准确度 你可能记得

00:03:01.185 --> 00:03:06.379
等于正确分类图像占图像总数的比例

00:03:06.379 --> 00:03:08.599
然后 我把这些统计数字打印出来

00:03:08.599 --> 00:03:14.419
运行后 我们得的准确度为 0.925 或 92.5%

00:03:14.419 --> 00:03:15.674
还不算差

00:03:15.675 --> 00:03:18.895
如果特征更多 你肯定可以进一步完善这个算法

00:03:18.895 --> 00:03:20.575
要看看如何完善

00:03:20.574 --> 00:03:22.169
我们可以观察

00:03:22.169 --> 00:03:26.314
分类错误的图像 了解错误标签内容

00:03:26.314 --> 00:03:29.129
你的任务是查看这些图像

00:03:29.129 --> 00:03:32.000
并考虑如何完善分类模型

