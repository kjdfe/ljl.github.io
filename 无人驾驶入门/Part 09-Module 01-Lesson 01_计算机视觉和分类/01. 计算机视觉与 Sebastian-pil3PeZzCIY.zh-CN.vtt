WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:02.390
现在 我们来到了课程的神奇部分

00:00:02.390 --> 00:00:03.930
我最喜欢的内容之一

00:00:03.930 --> 00:00:06.530
即计算机视觉 让无人驾驶车具备视觉

00:00:06.530 --> 00:00:10.065
当你睁开眼镜时

00:00:10.064 --> 00:00:13.830
你很神奇地就会知道 什么是咖啡杯

00:00:13.830 --> 00:00:16.339
什么是智能手机 什么是 Sebastian

00:00:16.339 --> 00:00:19.940
你的大脑不会告诉你原始的像素信息

00:00:19.940 --> 00:00:22.755
它会告诉你场景中的所有选项

00:00:22.754 --> 00:00:26.984
不幸的是 无人驾驶车在这方面不太擅长

00:00:26.984 --> 00:00:29.144
它们都安装有摄像头 像这里这个一样

00:00:29.144 --> 00:00:31.169
摄像头会生成图像

00:00:31.170 --> 00:00:32.815
比如这里的这个图

00:00:32.814 --> 00:00:35.669
而图像是一个由数字组成的大矩阵

00:00:35.670 --> 00:00:39.000
左上角有一个像素 像素 11

00:00:39.000 --> 00:00:41.054
它旁边是像素 21 和像素 31

00:00:41.054 --> 00:00:43.944
依次类推 直到我们得到像素 1024

00:00:43.944 --> 00:00:47.385
不用担心具体数字

00:00:47.384 --> 00:00:50.009
每个像素都有一个着色

00:00:50.009 --> 00:00:52.004
都有一定数量的红色

00:00:52.005 --> 00:00:53.920
一定数量的蓝色和绿色

00:00:53.920 --> 00:00:55.530
好的 机器就只能得到这些信息 也就是说

00:00:55.530 --> 00:00:57.505
机器不会像人一样 说 噢 我的天

00:00:57.505 --> 00:01:00.570
图像这里显然是一个反光镜

00:01:00.570 --> 00:01:02.820
它只会得到由像素组成的矩阵

00:01:02.820 --> 00:01:05.099
计算机视觉要做的 就是从巨大的图像

00:01:05.099 --> 00:01:09.899
数据矩阵中 提取能看到的对象

00:01:09.900 --> 00:01:12.125
接下来 想像一下

00:01:12.125 --> 00:01:14.234
现在 你得到了一幅停车标志的图像

00:01:14.234 --> 00:01:15.769
对于出现的每个数字

00:01:15.769 --> 00:01:17.784
你都有正确的着色数字

00:01:17.784 --> 00:01:21.030
你必须看到图像中哪里才是停车标志

00:01:21.030 --> 00:01:22.500
不是你自己 用你的大脑

00:01:22.500 --> 00:01:23.700
或你的视觉皮层来观察

00:01:23.700 --> 00:01:26.000
而是通过电脑软件来观察

