WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:04.280
Let's see exactly how a high-pass filter works.

00:00:04.280 --> 00:00:08.975
I mentioned that high pass filters detect big changes in intensity over a small area,

00:00:08.974 --> 00:00:12.800
and patterns of intensity can be best seen in a grayscale image.

00:00:12.800 --> 00:00:16.530
For example, if we put this image of a car through a high-pass filter,

00:00:16.530 --> 00:00:18.995
we expect the edges of the car to be detected,

00:00:18.995 --> 00:00:21.464
like the edge at the top of the car.

00:00:21.464 --> 00:00:26.120
At this point, the image goes from a very light area on the car to a dark background.

00:00:26.120 --> 00:00:28.445
And there are a lot of small areas like this

00:00:28.445 --> 00:00:30.984
that change from light to dark and vice versa.

00:00:30.984 --> 00:00:33.769
The complete filtered image might look like this,

00:00:33.770 --> 00:00:37.460
with the edges of the car and road lines emphasized in white.

00:00:37.460 --> 00:00:39.799
You can also see where there's no change or

00:00:39.799 --> 00:00:42.329
little change in intensity in the original picture,

00:00:42.329 --> 00:00:44.795
such as in these large areas of dark and light.

00:00:44.795 --> 00:00:49.145
A high-pass filter will block these areas out and turn the pixels black.

00:00:49.145 --> 00:00:52.460
The filters I'll be talking about are in the form of matrices,

00:00:52.460 --> 00:00:54.590
often called convolution kernels,

00:00:54.590 --> 00:00:57.425
which are just grids of numbers that modify an image.

00:00:57.424 --> 00:01:01.019
Here's an example of a high-pass filter that does edge detection.

00:01:01.020 --> 00:01:05.750
It's a three by three kernel whose elements all sum to zero.

00:01:05.750 --> 00:01:07.525
It's important that for edge detection,

00:01:07.525 --> 00:01:09.180
all of the elements sum to zero,

00:01:09.180 --> 00:01:14.025
because this filter is computing the difference or change between neighboring pixels.

00:01:14.025 --> 00:01:18.080
Differences are calculated by subtracting pixel values from one another.

00:01:18.079 --> 00:01:22.759
In this case, subtracting the value of the pixels that surround a center pixel.

00:01:22.760 --> 00:01:25.530
And if these kernel values do not add up to zero,

00:01:25.530 --> 00:01:27.599
that would mean that this calculated difference will be

00:01:27.599 --> 00:01:29.964
either positively or negatively weighted,

00:01:29.965 --> 00:01:34.859
and this would have the effect of lightening or darkening the entire filtered image.

00:01:34.859 --> 00:01:37.409
To apply this filter and input image,

00:01:37.409 --> 00:01:38.534
which I'll call F(x,

00:01:38.534 --> 00:01:40.875
y) for a function of x and y space,

00:01:40.875 --> 00:01:42.569
is convolved with this kernel,

00:01:42.569 --> 00:01:46.274
which I'll call K. This is called kernel convolution,

00:01:46.275 --> 00:01:48.930
and convolution is represented by an asterisk,

00:01:48.930 --> 00:01:51.105
not to be mistaken for multiplication.

00:01:51.105 --> 00:01:55.605
Kernel convolution is an important operation in computer vision applications,

00:01:55.605 --> 00:01:59.005
and it's the basis for convolutional neural networks.

00:01:59.004 --> 00:02:00.284
It involves taking a kernel,

00:02:00.284 --> 00:02:01.890
which is our small grid of numbers,

00:02:01.890 --> 00:02:04.545
and passing it over an image pixel by pixel,

00:02:04.545 --> 00:02:09.659
creating another edge detected output image based on what these numbers in the grid are.

00:02:09.659 --> 00:02:12.622
And we'll see that by changing the numbers in our kernel,

00:02:12.622 --> 00:02:17.129
we can create many different effects from edge detection to blurring in image.

00:02:17.129 --> 00:02:21.164
I walk through a mathematical example using this through by three edged detection filter.

00:02:21.164 --> 00:02:23.400
To better see the pixel level operations,

00:02:23.400 --> 00:02:25.469
I'll zoom in on this image right around

00:02:25.469 --> 00:02:28.465
this edge of the car to see the grayscale pixel values.

00:02:28.465 --> 00:02:31.500
First, for every pixel in this grayscale image,

00:02:31.500 --> 00:02:36.094
we put our kernel over it so that a pixel aligns with the center of the kernel.

00:02:36.094 --> 00:02:39.344
I'm just using this pixel as an example.

00:02:39.344 --> 00:02:43.935
Then, we look at the three by three grid of pixels centered around this one pixel.

00:02:43.935 --> 00:02:46.140
We then take the numbers in our kernel and

00:02:46.139 --> 00:02:49.649
multiply them with their corresponding pixel in pairs.

00:02:49.650 --> 00:02:53.120
So this pixel value in the top left corner,150,

00:02:53.120 --> 00:02:56.438
is multiplied by the kernel corner zero.

00:02:56.437 --> 00:03:00.627
And next to that, we multiply the value of 45 by negative one.

00:03:00.627 --> 00:03:02.984
And the next,25 by zero.

00:03:02.985 --> 00:03:05.085
And then we move on to the next row,

00:03:05.085 --> 00:03:09.420
and we do this for all nine pixel kernel value pairs.

00:03:09.419 --> 00:03:14.459
Notice that the center pixel with a value of 200 will be multiplied by four.

00:03:14.460 --> 00:03:19.064
Finally, these values are all summed up to get a new pixel value, 175.

00:03:19.064 --> 00:03:22.844
A high value like this means a pretty strong edge has been detected,

00:03:22.844 --> 00:03:26.729
which we can see just by looking at this three by three area in the image.

00:03:26.729 --> 00:03:30.299
It changes from very light to darker on top.

00:03:30.300 --> 00:03:34.380
The multipliers in the kernel are often called weights because they determine how

00:03:34.379 --> 00:03:39.449
important or how weighty a pixel is in forming a new output image.

00:03:39.449 --> 00:03:41.129
In this case for edge detection,

00:03:41.129 --> 00:03:43.382
the center pixel is the most important,

00:03:43.383 --> 00:03:48.085
followed by its closest pixels on the top and bottom and to its left and right.

00:03:48.085 --> 00:03:51.629
These are negative weights that increase the contrast in the image.

00:03:51.629 --> 00:03:54.604
The corners are the farthest away from the center pixel.

00:03:54.604 --> 00:03:57.709
And in this example, we don't give them any weight.

00:03:57.710 --> 00:03:59.990
So this weighted some, 175,

00:03:59.990 --> 00:04:03.520
becomes the value for the corresponding pixel at the same location,

00:04:03.520 --> 00:04:05.689
xy, in the output image,

00:04:05.689 --> 00:04:08.120
and you perform this convolution step for

00:04:08.120 --> 00:04:11.270
every pixel position in the original image until you

00:04:11.270 --> 00:04:13.850
have a complete output image that's about the same size as

00:04:13.849 --> 00:04:17.509
the input image with new filtered pixel values.

00:04:17.509 --> 00:04:20.599
The only other thing you need to consider is what to do at the edges of

00:04:20.600 --> 00:04:25.370
your image since the kernel cannot be nicely laid over three by three pixel values.

00:04:25.370 --> 00:04:28.649
Next, let's get a little more practice with these kinds of high-pass filters,

00:04:28.649 --> 00:04:31.000
then get into coding our own.

