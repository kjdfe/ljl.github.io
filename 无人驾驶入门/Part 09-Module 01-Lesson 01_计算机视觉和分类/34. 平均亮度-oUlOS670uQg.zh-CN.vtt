WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:03.720
在构建一个白天和夜间图像分类器时 你首先对输入图像

00:00:03.720 --> 00:00:07.865
进行了可视化 然后将其归一化为相同大小

00:00:07.865 --> 00:00:12.660
具体做法是 我们导入了常规资源并加载了图像数据集

00:00:12.660 --> 00:00:17.454
然后我们创建了一个所有图像机器标签的归一化列表

00:00:17.454 --> 00:00:20.104
最后 我们就能够可视化这些归一化之后的数据了

00:00:20.105 --> 00:00:25.045
在这里 我选择归一化列表里的第一幅图像机器标签

00:00:25.045 --> 00:00:28.505
然后 显示所选图像和部分相关信息

00:00:28.504 --> 00:00:32.365
你可以看到它的大小和标签 1 代表白天

00:00:32.365 --> 00:00:35.010
最后 我们就可以把所有这些图像

00:00:35.009 --> 00:00:37.989
分成两个类 白天和夜间了

00:00:37.990 --> 00:00:41.960
我们基于平均亮度水平来区分白天和夜间图像

00:00:41.960 --> 00:00:44.070
这会是一个单一值 请注意

00:00:44.070 --> 00:00:47.609
白天的图像比夜间图像的平均亮度更高

00:00:47.609 --> 00:00:49.979
要计算图像的平均亮度

00:00:49.979 --> 00:00:52.394
我们要使用 HSV 颜色空间

00:00:52.395 --> 00:00:54.965
具体来说 我们会使用明度 (value) 通道

00:00:54.965 --> 00:00:56.753
它用来测量亮度

00:00:56.753 --> 00:00:59.965
然后对该通道的像素值求和

00:00:59.965 --> 00:01:02.250
接下来 把总和除以图像面积

00:01:02.250 --> 00:01:05.340
得到图像的平均亮度

00:01:05.340 --> 00:01:08.579
首先 我把测试图像转换为 HSV 颜色空间

00:01:08.579 --> 00:01:10.739
我想看几张白天的图像和几张

00:01:10.739 --> 00:01:13.734
夜间的图像 找出两者的区别

00:01:13.734 --> 00:01:17.734
在本例中 我单独绘制 H、S 和 V 通道

00:01:17.734 --> 00:01:21.144
这是一张白天的图像 以及不同颜色通道 H、S、V

00:01:21.144 --> 00:01:24.622
我们可以看到 V 通道的天空亮度特别高

00:01:24.623 --> 00:01:30.090
这个分类基于的假设是 白天的天空比夜晚的天空亮度高

00:01:30.090 --> 00:01:33.810
因此 我们的下一步是 利用 V 通道确定平均亮度

00:01:33.810 --> 00:01:37.715
现在 我要定义一个函数 来找到图像的平均值

00:01:37.715 --> 00:01:40.939
这个函数 avg_brightness 会读入一个 RGB 图像

00:01:40.939 --> 00:01:44.399
第一步是把图像转换为 HSV 颜色空间

00:01:44.400 --> 00:01:48.555
然后 对 V 通道的所有像素值求和

00:01:48.555 --> 00:01:51.480
我使用 numpy 的 sum 函数来实现

00:01:51.480 --> 00:01:56.350
它会接受 HSV 图像的 V 通道 并对所有像素值求和

00:01:56.349 --> 00:01:58.229
然后 计算图像面积

00:01:58.230 --> 00:02:00.410
这里是 600 乘以 1100

00:02:00.409 --> 00:02:02.299
因为我们所有图像都归一化处理过

00:02:02.299 --> 00:02:04.530
要计算图像的平均亮度

00:02:04.530 --> 00:02:07.739
我们把这个亮度总和除以图像面积

00:02:07.739 --> 00:02:09.870
然后 这个函数会返回平均值

00:02:09.870 --> 00:02:11.715
我们得到了一个值

00:02:11.715 --> 00:02:14.689
图像的平均亮度或平均值

00:02:14.689 --> 00:02:16.199
下一步 我们要看看

00:02:16.199 --> 00:02:19.254
白天和夜间图像 以及它们的亮度值

00:02:19.254 --> 00:02:22.289
我们的目标是 看看它们的平均亮度 确定能否

00:02:22.289 --> 00:02:25.879
找到一个值 可以清晰区分白天和夜间图像

00:02:25.879 --> 00:02:28.590
我们先看看归一化后的 0 号图像

00:02:28.590 --> 00:02:30.360
我们知道 它是一幅白天图像

00:02:30.360 --> 00:02:33.795
我们看到 它的平均亮度大约是 175

00:02:33.794 --> 00:02:35.869
现在 我们看一幅夜间图像

00:02:35.870 --> 00:02:39.944
这个图像非常暗 平均亮度值约为 35

00:02:39.944 --> 00:02:42.495
我们要多看一些图像

00:02:42.495 --> 00:02:46.539
这是另一张白天图像 平均亮度约为 143

00:02:46.539 --> 00:02:49.034
现在 我们知道了几个值

00:02:49.034 --> 00:02:50.909
你可能在想 怎么才能用平均亮度

00:02:50.909 --> 00:02:54.799
来为每个图像预测一个标签呢

00:02:54.800 --> 00:02:56.814
0 代表夜间 1 代表白天

00:02:56.814 --> 00:02:59.425
因此 你需要找到阈值

00:02:59.425 --> 00:03:02.535
下一步就是把这个数据馈送到分类器

00:03:02.534 --> 00:03:05.759
分类器可能只是一个简单的条件语句

00:03:05.759 --> 00:03:09.664
检查亮度是否高于你定义的某个阈值

00:03:09.664 --> 00:03:12.854
这里 平均亮度值被看作一个特征

00:03:12.854 --> 00:03:15.810
特征是图像的可测量分量

00:03:15.810 --> 00:03:18.659
能够把一张图像和其他图像区分开来

00:03:18.659 --> 00:03:22.370
我们稍后就会学习如何测试这种模型的准确度

00:03:22.370 --> 00:03:24.270
接下来 我们在再解一下特征

00:03:24.270 --> 00:03:26.400
以及特征为什么对无人驾驶车非常有用

