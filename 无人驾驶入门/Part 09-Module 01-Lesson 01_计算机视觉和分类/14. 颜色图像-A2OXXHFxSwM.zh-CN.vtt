WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:03.325
你已经看过了一个例子 我们把一副图像

00:00:03.325 --> 00:00:06.130
分解为灰阶像素值的 2D 网格

00:00:06.129 --> 00:00:07.764
包括宽度和高度值

00:00:07.764 --> 00:00:10.119
但彩色图像有点不同

00:00:10.119 --> 00:00:16.390
彩色图像可以表示为值的 3D 立方体 包括宽度、高度和深度

00:00:16.390 --> 00:00:19.275
深度是颜色通道的数量

00:00:19.275 --> 00:00:23.964
大多数彩色图像都可以表示为三种颜色的组合：红

00:00:23.964 --> 00:00:26.039
绿、蓝

00:00:26.039 --> 00:00:29.919
它们被称为 RGB 图像 对于这些图像

00:00:29.920 --> 00:00:31.390
深度为 3

00:00:31.390 --> 00:00:35.950
我们可以把深度想象为堆积在一起的 3 个 2D 颜色层

00:00:35.950 --> 00:00:37.330
一层是红色

00:00:37.329 --> 00:00:39.054
一层是绿色 一层是蓝色

00:00:39.054 --> 00:00:40.704
堆积在一起时

00:00:40.704 --> 00:00:43.149
它们组成了一个完整的彩色图像

00:00:43.149 --> 00:00:46.824
彩色图像比灰阶图像包括的信息更多

00:00:46.825 --> 00:00:51.280
它们会增加不必要的复杂性 并且占用更多的内存空间

00:00:51.280 --> 00:00:55.929
但是 彩色图像对于某些分类任务非常有用

00:00:55.929 --> 00:01:00.365
例如 假设你想对这幅道路图像中的车道线进行分类

00:01:00.365 --> 00:01:02.425
其中一条线是黄色的 另一条是白色的

00:01:02.424 --> 00:01:04.840
但哪条是哪条呢 你可能看到

00:01:04.840 --> 00:01:08.270
这些车道线的灰阶密度稍有不同

00:01:08.269 --> 00:01:12.319
但差别很小 在不同照明条件下还会变化

00:01:12.319 --> 00:01:14.409
因此 这幅灰阶图像并没有提供

00:01:14.409 --> 00:01:18.280
足够的信息 我们无法区分黄色和白色车道线

00:01:18.280 --> 00:01:21.090
我们看看彩色图像 对比一下

00:01:21.090 --> 00:01:24.680
这里 我们能清楚看到 白色和黄色车道线的区别

00:01:24.680 --> 00:01:27.920
因此 我们也可以告诉机器 如何识别这种区别

00:01:27.920 --> 00:01:31.629
因为该识别任务是依赖于颜色的

00:01:31.629 --> 00:01:34.670
因此 我们必须使用彩色图像

00:01:34.670 --> 00:01:38.700
一般来说 当考虑计算机视觉应用时 比如识别车道线

00:01:38.700 --> 00:01:40.125
车辆或行人时

00:01:40.125 --> 00:01:43.870
你可以通过和自己的视觉类比 判断出色彩信息

00:01:43.870 --> 00:01:46.090
和彩色图像是否有用

00:01:46.090 --> 00:01:50.115
如果使用彩色识别对人类更简单

00:01:50.115 --> 00:01:53.290
那让算法来观察彩色图像也会更简单

