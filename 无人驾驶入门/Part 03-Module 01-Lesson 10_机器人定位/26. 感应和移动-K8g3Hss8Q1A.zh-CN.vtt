WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:05.000
哇 你已经基本上完成了谷歌自动驾驶汽车定位的编程

00:00:05.000 --> 00:00:08.000
即使你现在也许不是很明白

00:00:08.000 --> 00:00:10.000
让我来告诉你我们现在处于什么阶段

00:00:10.000 --> 00:00:13.000
我们谈论了度量更新 我们谈论了移动

00:00:13.000 --> 00:00:16.000
我们称这两个程序为 "sense" 和 "move"

00:00:16.000 --> 00:00:20.000
现在 定位并不是别的 而是 "sense" 和 "move" 的迭代

00:00:20.000 --> 00:00:24.000
这里会有一个初始的信度被投掷在循环里

00:00:24.000 --> 00:00:27.000
如果你首先感知 如果它来到了左边

00:00:27.000 --> 00:00:33.000
那么定位的循环就像这样——移动 感知 移动 感知 移动 感知

00:00:33.000 --> 00:00:36.000
移动 感知 移动 感知 一直循环

00:00:36.000 --> 00:00:40.000
每一次机器人移动 它会失去它在哪里的信息

00:00:40.000 --> 00:00:42.000
那是因为机器人移动是不准确的

00:00:42.000 --> 00:00:45.000
每一次它感知 它会获得信息

00:00:45.000 --> 00:00:47.000
那是被一个事实所证明 就是在移动之后

00:00:47.000 --> 00:00:51.000
概率分布有变得有点更加平展 更加延伸

00:00:51.000 --> 00:00:55.000
在感知之后 它会变得更加集中

00:00:55.000 --> 00:01:00.000
事实上 作为一个脚注 有一种度量信息的方式被称作"熵"

00:01:00.000 --> 00:01:02.000
这是很多种你能写它的方式中的其中一种

00:01:02.000 --> 00:01:04.000
[-Ʃp(xi)log p(xi)]

00:01:04.000 --> 00:01:07.000
是每个格点概率的对数似然的期望

00:01:07.000 --> 00:01:12.000
我们不会更进一步讨论细节 这是一种分布信息的度量方式

00:01:12.000 --> 00:01:18.000
能够被证明的是 更新和移动让熵值下降

00:01:18.000 --> 00:01:20.000
度量能够让它上升

00:01:20.000 --> 00:01:23.000
你真的在损失和获得信息

00:01:23.000 --> 00:01:26.000
我现在想要在代码中实现它

00:01:26.000 --> 00:01:29.000
除了我们之前有的两个度量 红色和绿色之外

00:01:29.000 --> 00:01:32.000
我将会给你两次移动 1和1

00:01:32.000 --> 00:01:34.000
这意味着机器人向右移动 然后再向右移动一次

00:01:34.000 --> 00:01:40.000
如果机器人先感知到了是红色 然后向右移动了一步 然后感知到是绿色

00:01:40.000 --> 00:01:45.000
然后再次向右移动一步 你能计算出这个后验分布吗？

00:01:45.000 --> 99:59:59.999
让我们以一个均匀的先验分布开始

