WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:06.000
让我们运行这个程序 我们发现最有可能的格子是第四个格子

00:00:06.000 --> 00:00:09.000
那是讲得通的 因为对这个世界 它最好地匹配了红色和红色

00:00:09.000 --> 00:00:12.000
到这里的红色和这里的红色

00:00:12.000 --> 00:00:15.000
在观察到第二个红色之后 机器人仍然向右移动一格

00:00:15.000 --> 00:00:19.000
然后发现它自己在第四个格子里 就像这里显示的一样

00:00:19.000 --> 00:00:23.000
现在我想祝贺你刚刚所写的代码

00:00:23.000 --> 00:00:26.000
它是一个部分 对于实现

00:00:26.000 --> 00:00:31.000
谷歌自动驾驶汽车定位方法的本质

00:00:31.000 --> 00:00:36.000
正如我开始所说的 特别重要就是汽车准确地知道

00:00:36.000 --> 00:00:39.000
它在那里 对于它行驶的道路的地图而言

00:00:39.000 --> 00:00:45.000
虽然道路不会被涂成绿色和红色 道路有着路标

00:00:45.000 --> 00:00:49.000
代替这里这些红色和绿色的格子

00:00:49.000 --> 00:00:54.000
我们把这些路标的颜色插入到道路的颜色当中

00:00:54.000 --> 00:00:58.000
它不仅仅是每一步一次观察 而是整个场地的观察

00:00:58.000 --> 00:01:00.000
整个照相机图片的观察

00:01:00.000 --> 00:01:02.000
你可以对一个照相图片做相同的事

00:01:02.000 --> 00:01:05.000
只要你能够将照片嵌入到你的模型当中

00:01:05.000 --> 00:01:08.000
用照片在你的度量之中

00:01:08.000 --> 00:01:13.000
那么一段不会比你现在所写的代码难上多少的代码

00:01:13.000 --> 00:01:18.000
可以为定位谷歌自动驾驶汽车服务

00:01:18.000 --> 00:01:26.000
你已经实现了一个主要的函数 这个函数使得谷歌汽车能够自动驾驶

00:01:26.000 --> 00:01:31.000
我认为你真的应该很高兴 为你自己自豪

00:01:31.000 --> 00:01:35.000
你应该对你自己说 我已经实现了定位

00:01:35.000 --> 00:01:39.000
现在到底是为什么需要花费谷歌如此长的时间去建立一个能够自我驾驶的产品呢

00:01:39.000 --> 00:01:44.000
真相是情况要更加复杂

00:01:44.000 --> 00:01:48.000
有时 道路正在铺设和重修 我们要处理这个问题

00:01:48.000 --> 00:01:54.000
但是你已经实现的就是谷歌自动驾驶汽车定位想法的核心

00:01:54.000 --> 99:59:59.999
让我来总结我们已经学习的精华部分

