WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:08.000
To explain how this works, I have to talk about high dimesional Gaussians.

00:00:08.000 --> 00:00:13.000
These are often called multivariate Gaussians.

00:00:13.000 --> 00:00:20.000
The mean is now a vector with 1 element for each of the dimensions.

00:00:20.000 --> 00:00:23.000
The variance here is replaced by what's called a co-variance,

00:00:23.000 --> 00:00:27.000
and it's a matrix with D rows and D columns,

00:00:27.000 --> 00:00:30.000
if the dimensionality of the estimate is D.

00:00:30.000 --> 00:00:36.000
The formula is something you have to get used to.

00:00:36.000 --> 00:00:41.000
I'm writing it out for you, but you never get to see this again.

00:00:41.000 --> 00:00:44.000
To tell you the truth, even I have to look up the formula for this class,

00:00:44.000 --> 00:00:48.000
so I don't have it in my head, and please, don't get confused.

00:00:48.000 --> 00:00:52.000
Let me explain it to you more intuitively.

00:00:52.000 --> 00:00:55.000
Here's a 2-dimensional space.

00:00:55.000 --> 00:01:00.000
A 2-dimensional Gaussian is defined over that space,

00:01:00.000 --> 00:01:05.000
and it's possible to draw the contour lines of the Gaussian. It might look like this.

00:01:05.000 --> 00:01:10.000
The mean of this Gaussian is this x0, y0 pair,

00:01:10.000 --> 00:01:14.000
and the co-variance now defines the spread of the Gaussian

00:01:14.000 --> 00:01:17.000
as indicated by these contour lines.

00:01:17.000 --> 00:01:21.000
A Gaussian with a small amount of uncertainty might look like this.

00:01:21.000 --> 00:01:25.000
It might be possible to have a fairly small uncertainty in 1 dimension,

00:01:25.000 --> 00:01:28.000
but a huge uncertainty in the other.

00:01:28.000 --> 00:01:32.000
Huge uncertainty in the x-dimension is small, and the y- dimension is large.

00:01:32.000 --> 00:01:36.000
When the Gaussian is tilted as showed over here,

00:01:36.000 --> 00:01:41.000
then the uncertainty of x and y is correlated, which means if I get information about x--

00:01:41.000 --> 00:01:46.000
it actually sits over here--that would make me believe that y probably sits

00:01:46.000 --> 00:01:50.000
somewhere over here. That's called correlation.

00:01:50.000 --> 00:01:57.000
I can explain to you the entire effect of estimating velocity and using it in filtering

00:01:57.000 --> 00:01:59.000
using Gaussians like these,

00:01:59.000 --> 00:02:01.000
and it becomes really simple.

00:02:01.000 --> 00:02:05.000
The problem I'm going to choose is a 1-dimensional motion example.

00:02:05.000 --> 00:02:09.000
Let's assume at t = 1, we see our object over here.

00:02:09.000 --> 00:02:11.000
A t = 2 right over here.

00:02:11.000 --> 00:02:14.000
A t = 3 over here.

00:02:14.000 --> 00:02:20.000
Then you would assume that at t = 4, the object sits over here,

00:02:20.000 --> 00:02:24.000
and the reason why you would assume this is--even though it's just seen these different

00:02:24.000 --> 00:02:29.000
discrete locations, you can infer from it there is actually velocity that drives the object

00:02:29.000 --> 00:02:32.000
to the right side to the point over here.

00:02:32.000 --> 00:02:35.000
Now how does the Kalman filter address this?

00:02:35.000 --> 00:02:37.838
This is the true beauty of the Kalman filter.

